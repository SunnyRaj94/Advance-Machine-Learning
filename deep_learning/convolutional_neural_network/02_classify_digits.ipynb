{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem statement :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to identify the digit in given images. We have total 70,000 images, out of which 49,000 are part of train images with the label of digit and rest 21,000 images are unlabeled (known as test images). Now, We need to identify the digit for test images. Public and Private split for test images are 40:60 and evaluation metric of this challenge is accuracy\n",
    "    https://drive.google.com/open?id=1-TavdjU2ohg5T6ZN1KUiWE9BNWu9_vhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing necessary library\n",
    "#importing matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "#importing seaborn\n",
    "import seaborn as sea\n",
    "#importing pandas \n",
    "import pandas as pd\n",
    "#importing numpy\n",
    "import numpy as np\n",
    "\n",
    "# importing my custom library file methods\n",
    "import sys\n",
    "sys.path.append('/home/admin3/ml_with_phoenix/deep_learning/lib_and_pkl_files/')\n",
    "from ipynb.fs.full.library import *\n",
    "\n",
    "#importing job-lib\n",
    "import joblib\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D,Flatten\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation = 'relu'))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=32,activation='relu'))\n",
    "classifier.add(Dense(units=20,activation='relu'))\n",
    "classifier.add(Dense(units=10,activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating computational array from Image data from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data_generator =ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### appending path of  train and test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train=pd.read_csv(\"/home/admin3/Documents/MyDoc/data_sets/Identify-numbers/Train_UQcUa52/train.csv\")\n",
    "class_test =pd.read_csv(\"/home/admin3/Documents/MyDoc/data_sets/Identify-numbers/Test_fCbTej3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_train_image = \"/home/admin3/Documents/MyDoc/data_sets/Identify-numbers/Train_UQcUa52/Images/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_with_classes(path,data_set,column_name):\n",
    "    return [path+image for image in data_set[column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train[\"full_path\"]=image_file_with_classes(path_of_train_image,class_train,'filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train.drop(['filename'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          full_path\n",
       "0      4  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "1      9  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "2      1  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "3      7  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "4      3  /home/admin3/Documents/MyDoc/data_sets/Identif..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test[\"full_path\"]=image_file_with_classes(path_of_test_image,class_test,'filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "      <td>/home/admin3/Documents/MyDoc/data_sets/Identif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                          full_path\n",
       "0  49000.png  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "1  49001.png  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "2  49002.png  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "3  49003.png  /home/admin3/Documents/MyDoc/data_sets/Identif...\n",
       "4  49004.png  /home/admin3/Documents/MyDoc/data_sets/Identif..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_train=class_train.astype(str)\n",
    "class_test=class_test.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = class_train[:37000]\n",
    "test_df = class_train[37000:]\n",
    "test_df =test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37000 validated image filenames belonging to 10 classes.\n",
      "Found 12000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_data_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                        x_col='full_path',\n",
    "                                                        target_size=(64,64),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        y_col='label')\n",
    "test_set = train_data_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                                        x_col='full_path',\n",
    "                                                        target_size=(64,64),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        y_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_test_image = \"/home/admin3/Documents/MyDoc/data_sets/Identify-numbers/Train_UQcUa52/Images/test/\"\n",
    "class_test[\"full_path\"]=image_file_with_classes(path_of_test_image,class_test,'filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/admin3/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "1157/1157 [==============================] - 53s 46ms/step - loss: 0.7822 - acc: 0.7090 - val_loss: 0.4418 - val_acc: 0.8562\n",
      "Epoch 2/10\n",
      "1157/1157 [==============================] - 54s 47ms/step - loss: 0.3710 - acc: 0.8773 - val_loss: 0.3562 - val_acc: 0.8847\n",
      "Epoch 3/10\n",
      "1157/1157 [==============================] - 61s 53ms/step - loss: 0.2970 - acc: 0.9018 - val_loss: 0.2949 - val_acc: 0.9067\n",
      "Epoch 4/10\n",
      "1157/1157 [==============================] - 72s 62ms/step - loss: 0.2521 - acc: 0.9196 - val_loss: 0.2664 - val_acc: 0.9182\n",
      "Epoch 5/10\n",
      "1157/1157 [==============================] - 56s 48ms/step - loss: 0.2211 - acc: 0.9302 - val_loss: 0.2390 - val_acc: 0.9267\n",
      "Epoch 6/10\n",
      "1157/1157 [==============================] - 53s 46ms/step - loss: 0.2040 - acc: 0.9358 - val_loss: 0.2359 - val_acc: 0.9325\n",
      "Epoch 7/10\n",
      "1157/1157 [==============================] - 53s 46ms/step - loss: 0.1929 - acc: 0.9388 - val_loss: 0.2060 - val_acc: 0.9375\n",
      "Epoch 8/10\n",
      "1157/1157 [==============================] - 52s 45ms/step - loss: 0.1806 - acc: 0.9435 - val_loss: 0.1915 - val_acc: 0.9415\n",
      "Epoch 9/10\n",
      "1157/1157 [==============================] - 53s 46ms/step - loss: 0.1704 - acc: 0.9472 - val_loss: 0.1985 - val_acc: 0.9395\n",
      "Epoch 10/10\n",
      "1157/1157 [==============================] - 57s 50ms/step - loss: 0.1634 - acc: 0.9501 - val_loss: 0.1638 - val_acc: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb6eb030cf8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set,epochs=10,batch_size=1,validation_data = test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicting output based on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "def open_image_and_convert_into_array(data_set,index,flag=False,classifier=None):\n",
    "    path =data_set[\"full_path\"][index]\n",
    "    img_plt = image.load_img(path,target_size=(64,64,1))\n",
    "    img = image.img_to_array(img_plt)/255\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    if flag:\n",
    "        print(\"digit in actual in image is :\",data_set[\"label\"][index])\n",
    "        print(\"digit predicted by model in image is :\",classifier.predict_classes(img))\n",
    "        plt.imshow(img_plt)\n",
    "        return img\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting digits in image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit in actual in image is : 8\n",
      "digit predicted by model in image is : [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_array=open_image_and_convert_into_array(class_train,111,True,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('/home/admin3/ml_with_phoenix/deep_learning/lib_and_pkl_files/digits_cnn_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
